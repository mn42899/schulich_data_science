{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, PrecisionRecallDisplay, precision_score, recall_score, roc_auc_score, RocCurveDisplay, roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import timedelta\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV #GridSearch is for hyperparameter tuning\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all tables\n",
    "customers = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/customers_final.csv')\n",
    "engagement = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/engagements_final.csv')\n",
    "marketing = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/marketing_final.csv')\n",
    "transactions = pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/transactions_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: marketing data at a customer level\n",
    "marketing_agg = marketing[marketing['response']=='Yes'].groupby('customer_id')['campaign_id'].count().to_frame()\n",
    "# step 2: aggregate transaction data at a customer level\n",
    "transactions_agg = transactions.groupby('customer_id').aggregate({'transaction_id':'count','transaction_amount':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: set customers and engagement index as customer_id\n",
    "customers.set_index('customer_id', inplace=True)\n",
    "engagement.set_index('customer_id', inplace=True)\n",
    "# step 4: join all tables\n",
    "joint_data = customers.join(engagement).join(transactions_agg).join(marketing_agg)\n",
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING & FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTV Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of LTV\n",
    "joint_data.groupby('customer_id')['transaction_amount'].sum()\n",
    "joint_data['LTV'] = joint_data.groupby('customer_id')['transaction_amount'].sum()\n",
    "joint_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data['LTV'].describe()\n",
    "# note: 75th percentile will be used as binary output for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of age entries are blank \n",
    "null_counts = joint_data['age'].isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNNImputer instance - this is to clean the age data since it will be used in modelling\n",
    "imputer = KNNImputer(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the imputer to the age column\n",
    "joint_data[['age']] = imputer.fit_transform(joint_data[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data['campaign_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over 20% of customers were not sent any marketing campaigns\n",
    "campaign_null_counts = joint_data['campaign_id'].isnull().sum()\n",
    "campaign_null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN used to make up for the null values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "joint_data[['campaign_id']] = imputer.fit_transform(joint_data[['campaign_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transaction_date to datetime\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Join Time (How long they have been a member)\n",
    "joint_data['Customer_Join_Time'] = pd.to_datetime(joint_data['last_purchase_date']) - pd.to_datetime(joint_data['join_date'])\n",
    "joint_data['Customer_Join_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg transaction amount\n",
    "joint_data['Avg_Transaction_Amount'] = (joint_data['LTV'])/(joint_data['transaction_id'])\n",
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Recent Purchase (in days)\n",
    "joint_data['most_recent_purchase_date'] = pd.to_datetime(joint_data['last_purchase_date'].max()) - pd.to_datetime(joint_data['last_purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an integer number of days for most recent purchase\n",
    "joint_data['most_recent_purchase_in_days'] = joint_data['most_recent_purchase_date'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an integer number of days for customer age\n",
    "joint_data['Customer_Jointime_in_days']=joint_data['Customer_Join_Time'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender for CATEGORICAL COLUMN \n",
    "def Gender_Categorical(x):\n",
    "    if x == 'Male':\n",
    "        return 1\n",
    "    elif x == 'Female':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data['Gender_Categorical'] = joint_data['gender'].apply(Gender_Categorical)\n",
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Frequency and Monetary: Higher values are better\n",
    "joint_data['SiteVisit_Score'] = pd.qcut(joint_data['number_of_site_visits'], 4, labels=[1, 2, 3, 4])\n",
    "joint_data['EmailOpen_Score'] = pd.qcut(joint_data['number_of_emails_opened'], 4, labels=[1, 2, 3, 4])\n",
    "joint_data['Click_Score'] = pd.qcut(joint_data['number_of_clicks'], 4, labels=[1, 2, 3, 4])\n",
    "\n",
    "# Combine scores to a single score\n",
    "joint_data['Engagement_Score'] = joint_data['SiteVisit_Score'].astype(int) + joint_data['EmailOpen_Score'].astype(int) + joint_data['Click_Score'].astype(int)\n",
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg Transaction Time = how often do they make a transaction (in days)\n",
    "joint_data['Avg_Transaction_Time'] = joint_data['Customer_Jointime_in_days']/joint_data['transaction_id']\n",
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LabelEncoder instance\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data\n",
    "joint_data['location_encoded'] = label_encoder.fit_transform(joint_data['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded integers to floats\n",
    "joint_data['location_encoded'] = joint_data['location_encoded'].astype(float)\n",
    "# it was found that this hurt when inserted as an input variable for all of the models as the accuracy scores for '1' were\n",
    "# well under 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF (1 MONTH, 3 MONTHS, 6 MONTHS, 12 MONTHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime type\n",
    "transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set reference date\n",
    "last_date = transactions['transaction_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rf(data, end_date, days_label):\n",
    "    rf = data.groupby('customer_id').agg(\n",
    "        recency = ('transaction_date', lambda x: (end_date - x.max()).days),\n",
    "        frequency = ('transaction_id', 'count'),\n",
    "        monetary = ('transaction_amount', 'sum')\n",
    "    ).rename(columns={\n",
    "        'recency': f'Recency_{days_label}',\n",
    "        'frequency': f'Frequency_{days_label}',\n",
    "        'monetary': f'Monetary_{days_label}'\n",
    "    })\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time periods\n",
    "days_30 = last_date - timedelta(days=30)\n",
    "last_30_days = transactions[(transactions['transaction_date'] > days_30) & (transactions['transaction_date'] <= last_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_30 = calculate_rf(last_30_days, last_date, '30')\n",
    "rf_30\n",
    "# Conclusion: not enough data to conduct any modeling for rf on last 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_90 = last_date - timedelta(days=90)\n",
    "last_90_days = transactions[(transactions['transaction_date'] > days_90) & (transactions['transaction_date'] <= last_date)]\n",
    "rf_90 = calculate_rf(last_90_days, last_date, '90')\n",
    "rf_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf Score Creation for 3 months\n",
    "# Scoring Recency: Lower recency is better\n",
    "rf_90['R_Score'] = pd.qcut(rf_90['Recency_90'], 4, labels=[4, 3, 2, 1])\n",
    "\n",
    "# Scoring Frequency and Monetary: Higher values are better\n",
    "rf_90['F_Score'] = pd.qcut(rf_90['Frequency_90'], 4, labels=[1, 2, 3, 4])\n",
    "rf_90['M_Score'] = pd.qcut(rf_90['Monetary_90'], 4, labels=[1, 2, 3, 4])\n",
    "\n",
    "# Combine scores to a single score\n",
    "rf_90['rf_Score'] = rf_90['R_Score'].astype(int) + rf_90['F_Score'].astype(int)\n",
    "rf_90.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_90 = pd.merge(rf_90, joint_data[['LTV','age', 'Customer_Join_Time', 'Avg_Transaction_Amount', 'Customer_Jointime_in_days',\n",
    "                                      'SiteVisit_Score', 'EmailOpen_Score', 'Click_Score',\n",
    "                                      'Engagement_Score', 'Gender_Categorical',\n",
    "                                      'Avg_Transaction_Time', 'campaign_id',\n",
    "                                      'transaction_id']], on='customer_id', how='left')\n",
    "rf_90.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_180 = last_date - timedelta(days=180)\n",
    "last_180_days = transactions[(transactions['transaction_date'] > days_180) & (transactions['transaction_date'] <= last_date)]\n",
    "rf_180 = calculate_rf(last_180_days, last_date, '180')\n",
    "rf_180.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf Score Creation for 6 months\n",
    "# Scoring Recency: Lower recency is better\n",
    "rf_180['R_Score'] = pd.qcut(rf_180['Recency_180'], 4, labels=[4, 3, 2, 1])\n",
    "\n",
    "# Scoring Frequency and Monetary: Higher values are better\n",
    "rf_180['F_Score'] = pd.qcut(rf_180['Frequency_180'], 4, labels=[1, 2, 3, 4])\n",
    "rf_180['M_Score'] = pd.qcut(rf_180['Monetary_180'], 4, labels=[1, 2, 3, 4])\n",
    "\n",
    "# Combine scores to a single score\n",
    "rf_180['rf_Score'] = rf_180['R_Score'].astype(int) + rf_180['F_Score'].astype(int)\n",
    "rf_180.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_180 = pd.merge(rf_180, joint_data[['LTV','age', 'Customer_Join_Time', 'Avg_Transaction_Amount', 'Customer_Jointime_in_days',\n",
    "                                      'SiteVisit_Score', 'EmailOpen_Score', 'Click_Score',\n",
    "                                      'Engagement_Score', 'Gender_Categorical',\n",
    "                                      'Avg_Transaction_Time', 'campaign_id',\n",
    "                                      'transaction_id']], on='customer_id', how='left')\n",
    "rf_180.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_365 = last_date - timedelta(days=365)\n",
    "last_365_days = transactions[(transactions['transaction_date'] > days_365) & (transactions['transaction_date'] <= last_date)]\n",
    "rf_365 = calculate_rf(last_365_days, last_date, '365')\n",
    "rf_365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf Score Creation for 1 year\n",
    "# Scoring Recency: Lower recency is better\n",
    "rf_365['R_Score'] = pd.qcut(rf_365['Recency_365'], 4, labels=[4, 3, 2, 1])\n",
    "\n",
    "# Scoring Frequency and Monetary: Higher values are better\n",
    "rf_365['F_Score'] = pd.qcut(rf_365['Frequency_365'], 4, labels=[1, 2, 3, 4])\n",
    "rf_365['M_Score'] = pd.qcut(rf_365['Monetary_365'], 4, labels=[1, 2, 3, 4])\n",
    "\n",
    "# Combine scores to a single score\n",
    "rf_365['rf_Score'] = rf_365['R_Score'].astype(int) + rf_365['F_Score'].astype(int)\n",
    "rf_365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_365 = pd.merge(rf_365, joint_data[['LTV','age', 'Customer_Join_Time', 'Avg_Transaction_Amount', 'Customer_Jointime_in_days',\n",
    "                                      'SiteVisit_Score', 'EmailOpen_Score', 'Click_Score',\n",
    "                                      'Engagement_Score', 'Gender_Categorical',\n",
    "                                      'Avg_Transaction_Time', 'campaign_id',\n",
    "                                      'transaction_id']], on='customer_id', how='left')\n",
    "rf_365.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL BUILDING AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 MONTHS RF - LOGISTICAL REGRESSION (THIS WAS CHOSEN AS THE MDOEL OF CHOICE FOR RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data['LTV'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75th percentile or better for the joint_data['LTV'] is used for binary output because we are trying to predict the highest value customers\n",
    "# and this is reflective of the highest $$$ value customers over the lifetime of transactions\n",
    "rf_90['binary_output'] = rf_90['LTV'].apply(lambda x: 1 if x>=11275.797500 else 0)\n",
    "rf_90['binary_output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will predict whether there will be a large amount of high value customers \n",
    "X_90 = rf_90[['age','Customer_Jointime_in_days', 'Engagement_Score', 'transaction_id',\n",
    "                'Gender_Categorical','Avg_Transaction_Time', 'campaign_id',\n",
    "                'R_Score','F_Score']]\n",
    "y_90 = rf_90['binary_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve 30% for testing\n",
    "X_train_90, X_test_90, y_train_90, y_test_90 = train_test_split(X_90,y_90, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline that includes these transformations\n",
    "numeric_columns_90 = ['age','Customer_Jointime_in_days', 'Engagement_Score', \n",
    "                      'transaction_id','Avg_Transaction_Time', \n",
    "                      'campaign_id', 'R_Score','F_Score']\n",
    "categorical_columns_90 = ['Gender_Categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pre-processing pipeline which includes the steps of Scaling numeric variables and encoding categoricals\n",
    "preprocessor_90 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',MinMaxScaler(), numeric_columns_90),\n",
    "        ('cat',OneHotEncoder(handle_unknown='ignore'),categorical_columns_90)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 3 models with cross validation to see which ones work best for this data\n",
    "knn_90 = KNeighborsClassifier()\n",
    "logreg_90 = LogisticRegression()\n",
    "nb_90 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to determine in general which model works best for the given problem\n",
    "knn_scores_90 = cross_val_score(knn_90, X_train_90, y_train_90, scoring='f1', cv=5)\n",
    "logreg_scores_90 = cross_val_score(logreg_90, X_train_90, y_train_90, scoring='f1', cv=5)\n",
    "nb_scores_90 = cross_val_score(nb_90, X_train_90, y_train_90, scoring='f1', cv=5)\n",
    "print(f\"knn_scores_90: {np.mean(knn_scores_90)}\")\n",
    "print(f\"logreg_scores_90: {np.mean(logreg_scores_90)}\")\n",
    "print(f\"nb_scores_90: {np.mean(nb_scores_90)}\")\n",
    "\n",
    "# KNN ruled out because it has lowest score Logreg will be put through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline\n",
    "pipeline_90 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_90),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GRID SEARCH to find the best combination of hyperparameters for our problem\n",
    "param_grid_90 = {\n",
    "  'classifier__C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Algorithms to use in the optimization problem\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Norm used in the penalization\n",
    "    'classifier__max_iter': [100, 200, 300]  # Maximum number of iterations taken for the solvers to converge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_90 = GridSearchCV(pipeline_90, param_grid_90, cv=5, verbose=1, scoring='f1')\n",
    "grid_search_90.fit(X_train_90,y_train_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifier_90 = LogisticRegression(\n",
    "    C=grid_search_90.best_params_['classifier__C'],\n",
    "    solver=grid_search_90.best_params_['classifier__solver'],\n",
    "    penalty=grid_search_90.best_params_['classifier__penalty'],\n",
    "    max_iter=grid_search_90.best_params_['classifier__max_iter']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_90 = Pipeline(steps=\n",
    "                          [\n",
    "                              ('preprocessor',preprocessor_90),\n",
    "                              ('classifier',final_classifier_90)\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_90.fit(X_train_90,y_train_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_90 = final_pipeline_90.predict(X_test_90)\n",
    "probs_90 = final_pipeline_90.predict_proba(X_test_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 6 month period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "report_90 = classification_report(y_test_90, pred_90)\n",
    "print(report_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor - 3 MONTH RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestRegressor object\n",
    "model_90RFR = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_90RFR, X_test_90RFR, y_train_90RFR, y_test_90RFR = train_test_split(X_90, y_90, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model_90RFR.fit(X_train_90RFR, y_train_90RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_90RFR= model_90RFR.predict(X_test_90RFR)\n",
    "y_pred_90RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary by applying a threshold\n",
    "threshold_90RFR = 0.5\n",
    "y_pred_binary_90RFR = (y_pred_90RFR > threshold_90RFR).astype(int)\n",
    "\n",
    "\n",
    "#  RandomForestRegressor Scores - Using RF Scores over 3 month period\n",
    "print(classification_report(y_test_90RFR, y_pred_binary_90RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75th percentile or better for the joint_data['LTV'] is used for binary output because we are trying to predict the highest value customers\n",
    "# and this is reflective of the highest $$$ value customers over the lifetime of transactions\n",
    "rf_180['binary_output'] = rf_180['LTV'].apply(lambda x: 1 if x>=11275.797500 else 0)\n",
    "rf_180['binary_output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will predict whether there will be a large amount of high value customers \n",
    "X_180 = rf_180[['age','Customer_Jointime_in_days', 'Engagement_Score', 'transaction_id',\n",
    "                'Gender_Categorical','Avg_Transaction_Time', 'campaign_id',\n",
    "                'R_Score','F_Score']]\n",
    "y_180 = rf_180['binary_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve 30% for testing\n",
    "X_train_180, X_test_180, y_train_180, y_test_180 = train_test_split(X_180,y_180, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline that includes these transformations\n",
    "numeric_columns_180 = ['age','Customer_Jointime_in_days', 'Engagement_Score', 'transaction_id',\n",
    "                       'Avg_Transaction_Time', 'campaign_id', 'R_Score','F_Score']\n",
    "categorical_columns_180 = ['Gender_Categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pre-processing pipeline which includes the steps of Scaling numeric variables and encoding categoricals\n",
    "preprocessor_180 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',MinMaxScaler(), numeric_columns_180),\n",
    "        ('cat',OneHotEncoder(handle_unknown='ignore'),categorical_columns_180)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 3 models with cross validation to see which ones work best for this data\n",
    "knn_180 = KNeighborsClassifier()\n",
    "logreg_180 = LogisticRegression()\n",
    "nb_180 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to determine in general which model works best for the given problem\n",
    "knn_scores_180 = cross_val_score(knn_180, X_train_180, y_train_180, scoring='f1', cv=5)\n",
    "logreg_scores_180 = cross_val_score(logreg_180, X_train_180, y_train_180, scoring='f1', cv=5)\n",
    "nb_scores_180 = cross_val_score(nb_180, X_train_180, y_train_180, scoring='f1', cv=5)\n",
    "print(f\"knn_scores_180: {np.mean(knn_scores_180)}\")\n",
    "print(f\"logreg_scores_180: {np.mean(logreg_scores_180)}\")\n",
    "print(f\"nb_scores_180: {np.mean(nb_scores_180)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline\n",
    "pipeline_180 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_180),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GRID SEARCH to find the best combination of hyperparameters for our problem\n",
    "param_grid_180 = {\n",
    "  'classifier__C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Algorithms to use in the optimization problem\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Norm used in the penalization\n",
    "    'classifier__max_iter': [100, 200, 300]  # Maximum number of iterations taken for the solvers to converge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_180 = GridSearchCV(pipeline_180, param_grid_180, cv=5, verbose=1, scoring='f1')\n",
    "grid_search_180.fit(X_train_180,y_train_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifier_180 = LogisticRegression(\n",
    "    C=grid_search_180.best_params_['classifier__C'],\n",
    "    solver=grid_search_180.best_params_['classifier__solver'],\n",
    "    penalty=grid_search_180.best_params_['classifier__penalty'],\n",
    "    max_iter=grid_search_180.best_params_['classifier__max_iter']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_180 = Pipeline(steps=\n",
    "                          [\n",
    "                              ('preprocessor',preprocessor_180),\n",
    "                              ('classifier',final_classifier_180)\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_180.fit(X_train_180,y_train_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_180 = final_pipeline_180.predict(X_test_180)\n",
    "probs_180 = final_pipeline_180.predict_proba(X_test_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 6 month period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "report_180 = classification_report(y_test_180, pred_180)\n",
    "print(report_180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor - 6 MONTH RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestRegressor object\n",
    "model_180RFR = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_180RFR, X_test_180RFR, y_train_180RFR, y_test_180RFR = train_test_split(X_180, y_180, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model_180RFR.fit(X_train_180RFR, y_train_180RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_180RFR= model_180RFR.predict(X_test_180RFR)\n",
    "y_pred_180RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary by applying a threshold\n",
    "threshold_180RFR = 0.5\n",
    "y_pred_binary_180RFR = (y_pred_180RFR > threshold_180RFR).astype(int)\n",
    "\n",
    "\n",
    "#  RandomForestRegressor Scores - Using RF Scores over 6 month period\n",
    "print(classification_report(y_test_180RFR, y_pred_binary_180RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75th percentile or better for the joint_data['LTV'] is used for binary output because we are trying to predict the highest value customers\n",
    "# and this is reflective of the highest $$$ value customers over the lifetime of transactions\n",
    "rf_365['binary_output'] = rf_365['LTV'].apply(lambda x: 1 if x>=11275.797500 else 0)\n",
    "rf_365['binary_output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will predict whether there will be a large amount of high value customers \n",
    "X_365 = rf_365[['age','Customer_Jointime_in_days', 'Engagement_Score', 'transaction_id'\n",
    "                ,'Avg_Transaction_Time', 'campaign_id', \n",
    "                'R_Score','F_Score', 'Gender_Categorical']]\n",
    "y_365 = rf_365['binary_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve 30% for testing\n",
    "X_train_365, X_test_365, y_train_365, y_test_365 = train_test_split(X_365,y_365, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline that includes these transformations\n",
    "numeric_columns_365 = ['age','Customer_Jointime_in_days', 'Engagement_Score', \n",
    "                      'transaction_id','Avg_Transaction_Time', \n",
    "                      'campaign_id', 'R_Score','F_Score']\n",
    "categorical_columns_365 = ['Gender_Categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pre-processing pipeline which includes the steps of Scaling numeric variables and encoding categoricals\n",
    "preprocessor_365 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',MinMaxScaler(), numeric_columns_365),\n",
    "        ('cat',OneHotEncoder(handle_unknown='ignore'),categorical_columns_365)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 3 models with cross validation to see which ones work best for this data\n",
    "knn_365 = KNeighborsClassifier()\n",
    "logreg_365 = LogisticRegression()\n",
    "nb_365 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to determine in general which model works best for the given problem\n",
    "knn_scores_365 = cross_val_score(knn_365, X_train_365, y_train_365, scoring='f1', cv=5)\n",
    "logreg_scores_365 = cross_val_score(logreg_365, X_train_365, y_train_365, scoring='f1', cv=5)\n",
    "nb_scores_365 = cross_val_score(nb_365, X_train_365, y_train_365, scoring='f1', cv=5)\n",
    "print(f\"knn_scores_365: {np.mean(knn_scores_365)}\")\n",
    "print(f\"logreg_scores_365: {np.mean(logreg_scores_365)}\")\n",
    "print(f\"nb_scores_365: {np.mean(nb_scores_365)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our pipeline\n",
    "pipeline_365 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_365),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, solver='lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GRID SEARCH to find the best combination of hyperparameters for our problem\n",
    "param_grid_365 = {\n",
    "  'classifier__C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Algorithms to use in the optimization problem\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],  # Norm used in the penalization\n",
    "    'classifier__max_iter': [100, 200, 300]  # Maximum number of iterations taken for the solvers to converge\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_365 = GridSearchCV(pipeline_365, param_grid_365, cv=5, verbose=1, scoring='f1')\n",
    "grid_search_365.fit(X_train_365,y_train_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifier_365 = LogisticRegression(\n",
    "    C=grid_search_365.best_params_['classifier__C'],\n",
    "    solver=grid_search_365.best_params_['classifier__solver'],\n",
    "    penalty=grid_search_365.best_params_['classifier__penalty'],\n",
    "    max_iter=grid_search_365.best_params_['classifier__max_iter']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_365 = Pipeline(steps=\n",
    "                          [\n",
    "                              ('preprocessor',preprocessor_365),\n",
    "                              ('classifier',final_classifier_365)\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_365.fit(X_train_365,y_train_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_365 = final_pipeline_365.predict(X_test_365)\n",
    "probs_365 = final_pipeline_365.predict_proba(X_test_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 1 year period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "report_365 = classification_report(y_test_365, pred_365)\n",
    "print(report_365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestRegressor - 1 YEAR RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestRegressor object\n",
    "model_365RFR = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# Splitting the data into training and testing sets\n",
    "X_train_365RFR, X_test_365RFR, y_train_365RFR, y_test_365RFR = train_test_split(X_365, y_365, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model_365RFR.fit(X_train_365RFR, y_train_365RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_365RFR= model_365RFR.predict(X_test_365RFR)\n",
    "y_pred_365RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary by applying a threshold\n",
    "threshold_365RFR = 0.5\n",
    "y_pred_binary_365RFR = (y_pred_365RFR > threshold_365RFR).astype(int)\n",
    "# Logistical Regression - Using RF Scores over 1 year period (after building pipeline and using GridSearch)\n",
    "print(classification_report(y_test_365RFR, y_pred_binary_365RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 3 month period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "print(f\"knn_scores_90: {np.mean(knn_scores_90)}\")\n",
    "print(f\"logreg_scores_90: {np.mean(logreg_scores_90)}\")\n",
    "print(f\"nb_scores_90: {np.mean(nb_scores_90)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistical Regression - Using RF Scores over 3 month period (after building pipeline and using GridSearch)\n",
    "report_90 = classification_report(y_test_90, pred_90)\n",
    "print(report_90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the preprocessor and the classifier from the pipeline\n",
    "preprocessor_90 = final_pipeline_90.named_steps['preprocessor']\n",
    "classifier_90 = final_pipeline_90.named_steps['classifier']\n",
    "\n",
    "# Get the feature names after preprocessing\n",
    "feature_names_90 = np.hstack([\n",
    "    preprocessor_90.transformers_[0][1].get_feature_names_out(),\n",
    "    preprocessor_90.transformers_[1][1].get_feature_names_out()\n",
    "])\n",
    "\n",
    "# Get the coefficients with feature names\n",
    "coefficients_90 = pd.DataFrame({\n",
    "    'Feature': feature_names_90,\n",
    "    'Coefficient': classifier.coef_[0]\n",
    "})\n",
    "\n",
    "print(coefficients_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RandomForestRegressor Scores - Using RF Scores over 3 month period\n",
    "print(classification_report(y_test_90RFR, y_pred_binary_90RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 6 month period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "print(f\"knn_scores_180: {np.mean(knn_scores_180)}\")\n",
    "print(f\"logreg_scores_180: {np.mean(logreg_scores_180)}\")\n",
    "print(f\"nb_scores_180: {np.mean(nb_scores_180)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistical Regression - Using RF Scores over 6 month period (after building pipeline and using GridSearch)\n",
    "report_180 = classification_report(y_test_180, pred_180)\n",
    "print(report_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the preprocessor and the classifier from the pipeline\n",
    "preprocessor_180 = final_pipeline_180.named_steps['preprocessor']\n",
    "classifier_180 = final_pipeline_180.named_steps['classifier']\n",
    "\n",
    "# Get the feature names after preprocessing\n",
    "feature_names_180 = np.hstack([\n",
    "    preprocessor_180.transformers_[0][1].get_feature_names_out(),\n",
    "    preprocessor_180.transformers_[1][1].get_feature_names_out()\n",
    "])\n",
    "\n",
    "# Get the coefficients with feature names\n",
    "coefficients_180 = pd.DataFrame({\n",
    "    'Feature': feature_names_180,\n",
    "    'Coefficient': classifier.coef_[0]\n",
    "})\n",
    "\n",
    "print(coefficients_180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RandomForestRegressor Scores - Using RF Scores over 6 month period\n",
    "print(classification_report(y_test_180RFR, y_pred_binary_180RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Scores for KNN, LogReg, and NB - Using RF Scores over 1 year period (before building pipeline and using GridSearch)\n",
    "# Logreg chosen due to having highest score\n",
    "print(f\"knn_scores_365: {np.mean(knn_scores_365)}\")\n",
    "print(f\"logreg_scores_365: {np.mean(logreg_scores_365)}\")\n",
    "print(f\"nb_scores_365: {np.mean(nb_scores_365)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistical Regression - Using RF Scores over 1 year period (after building pipeline and using GridSearch)\n",
    "report_365 = classification_report(y_test_365, pred_365)\n",
    "print(report_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the preprocessor and the classifier from the pipeline\n",
    "preprocessor_365 = final_pipeline_365.named_steps['preprocessor']\n",
    "classifier_365 = final_pipeline_365.named_steps['classifier']\n",
    "\n",
    "# Get the feature names after preprocessing\n",
    "feature_names_365 = np.hstack([\n",
    "    preprocessor_365.transformers_[0][1].get_feature_names_out(),\n",
    "    preprocessor_365.transformers_[1][1].get_feature_names_out()\n",
    "])\n",
    "\n",
    "# Get the coefficients with feature names\n",
    "coefficients_365 = pd.DataFrame({\n",
    "    'Feature': feature_names_365,\n",
    "    'Coefficient': classifier.coef_[0]\n",
    "})\n",
    "\n",
    "print(coefficients_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RandomForestRegressor Scores - Using RF Scores over 1 year period\n",
    "print(classification_report(y_test_365RFR, y_pred_binary_365RFR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
